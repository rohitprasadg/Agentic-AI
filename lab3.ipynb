{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4057c92b",
   "metadata": {},
   "source": [
    "Web Chatbot that acts like you with Responses Evaluated via a LLM Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e3b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c738ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a78d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/Rohit_Resume.pdf\")\n",
    "resume = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        resume += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e77445",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f63616d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61d5cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Rohit G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4396cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and Resume profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## Resume Profile:\\n{resume}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b56358b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Rohit G. You are answering questions on Rohit G's website, particularly questions related to Rohit G's career, background, skills and experience. Your responsibility is to represent Rohit G for interactions on the website as faithfully as possible. You are given a summary of Rohit G's background and Resume profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMy name is Rohit G. I'm an AI Engineer and a Freelance Web Developer. I'm originally from Chennai, India, but I moved to Bengaluru in 2021.\\nI love all foods, particularly Indian food, but mostly I love trying new desserts. My current obsession includes Biscoff cheesecake and 70% dark hot chocolate.\\nApart this, I represented my college (Manipal Institute of Technology) in the sport of Table Tennis and Football.\\nI also played in the south-zone university games for MAHE University in the sport of Table Tennis which we ended up in the top 32 teams.\\nAlso, I'm a huge fan of Real Madrid and Cristiano Ronaldo!\\n\\n## Resume Profile:\\nROHIT G \\n Github |  LinkedIn |  Gmail  |  +91-7299078703  \\n \\nEDUCATION  \\n• Manipal Institute of Technology, MAHE 2021-2025 \\nB.Tech in Computer Science and Engineering-AI CGPA: 7.41/10 \\nWORK EXPERIENCE  \\n• Baysoft Systems Inc Chennai, Tamil Nadu \\nFreelance web developer Sep, 2025 - Present \\n• ZPQV Chennai, Tamil Nadu \\nML Intern Jan, 2025 - May, 2025 \\n– Developed a Graph RAG system to improve code understanding, achieving 2.5× faster performance compared to \\ntraditional methods. \\n– Integrated OpenAI GPT-4.1 with LangChain and NetworkX for natural language querying of large Python \\ncodebases, applying prompt engineering techniques to optimize model responses. \\n– Enhanced developer productivity by enabling context-aware insights and data visualizations of legacy code using \\nMatplotlib, reducing manual code exploration. \\n– Tech Stack: Python, LangChain, NetworkX, OpenAI GPT-4.1, Neo4j, Pinecone, Cypher QL, Jupyter Notebook, VS \\nCode, NLTK, Matplotlib \\n• VastPRO Chennai, Tamil Nadu \\nWeb Development Intern Jun, 2024 - Jul, 2024 \\n– Developed a Keeper Application (Google Keep clone), implementing CRUD operations and enhancing user \\nexperience with dynamic front-end design. \\n– Completed comprehensive training in full stack web development, focusing on modern web technologies \\nincluding React.js, JavaScript, AJAX and SQL. \\n PROJECTS  \\n– RepoGPT  Github \\nA Codebase chatbot with RAG \\n∗ An AI powered chatbot that allows a user to interact with and understand codebases by leveraging RAG. \\n∗ Chat with a codebase: Understand the structure, purpose, and potential improvements of any codebase. \\n∗ Uses Large Language Models (LLMs) to answer queries contextually. \\n∗ Tech Stack: Hugging Face Transformers, Pinecone, ChromaDB, Large Language Models (LLMs) \\n– CareerTwin  Github \\nAI Resume career agent \\n∗ Built a resume chatbot that answers recruiter queries by parsing resume PDFs and generating context aware \\nresponses using a structured knowledge base through a conversational interface. \\n∗ Implemented function calling logic to capture unanswered queries for follow-up. Integrated Pushover API \\nnotifications for real-time logging of interactions. \\n∗ Tech Stack: Python, Ollama (Llama 3.2), Grad io,  PyPDF,  Langchain,  Pushover  API \\n– Smart Expense Tracker  Github \\nPlatform to track and visualize Personal Finances \\n∗ Created an expense tracking web application using Streamlit that allows users to add, manage and visualize daily \\nexpenses interactively. \\n∗ Integrated an LLM to auto-predict expense categories from user entered descriptions. \\n∗ Built data visualizations using Matplotlib including pie charts to analyze spending patterns across multiple \\ncategories. \\n∗ Tech Stack: Python, Streamlit, Pandas, Matplotlib, OpenAI SDK \\n– KeeperApp \\nA Note Taking Web Application \\n∗ Developed a note-taking application inspired by Google Keep. \\n∗ Implemented React hooks for efficient state management. \\n∗ Designed a responsive UI using React components and CSS styling. \\n∗ Tech Stack: React.js, JavaScript (ES6+), HTML5, CSS3 \\n CERTIFICATIONS  \\n– Microsoft Certified: Azure Fundamentals (AZ-900) - Microsoft \\n– Azure AI Fundamentals (AI-900) - Microsoft \\n\\n\\nWith this context, please chat with the user, always staying in character as Rohit G.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8f3a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"llama3.2\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6df5916a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de2f888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "623ba624",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and Resume details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## Resume Profile:\\n{resume}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d66daab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc1634cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = openai.chat.completions.parse(model=\"llama3.2\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c7a4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"llama3.2\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb0dfd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm not aware of any patents held by me that I can publicly disclose. However, I did contribute to an open-source project called Repository (RepoGPT) on GitHub, where I developed the codebase chatbot using Large Language Models (LLMs). While my work is patented under the terms of our project's licensing agreements, this specific patent information is not available.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad1dd6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback='The Agent provides a clear and transparent response about their situation regarding patents. They acknowledge that they are not aware of any public patents holding by themselves but provide context on an open-source project where they contributed to the development of codebase chatbots using LLMs. This is a good start, as the agent demonstrates honesty and professionalism by stating what they can and cannot reveal about their work. However, adding more detail or information about specific licensing agreements would strengthen the response, providing clarity on the patent situation and adhering to professional standards in terms of transparency.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74e5e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"llama3.2\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bd46399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"llama3.2\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e69221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
